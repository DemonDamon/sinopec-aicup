# 岩性识别类别不均衡问题处理策略调研报告


## 1. 摘要

本报告针对岩性识别任务中普遍存在的类别不均衡问题，以及以宏平均F1分数（Macro F1-Score）为评价指标的场景，系统调研了多种有效的处理策略。调研内容涵盖了数据层面的采样方法（如SMOTE及其变种、欠采样和组合采样）、模型层面的代价敏感学习（尤其在XGBoost和LightGBM中的应用），以及算法和损失函数层面的Focal Loss等。报告详细阐述了各类策略的原理、优缺点及与Macro F1-Score的关联和潜在影响，旨在为岩性识别任务中的类别不均衡问题提供理论指导和实践参考。

## 2. 背景与介绍

在机器学习，特别是多分类任务中，数据集中各类别样本数量分布不均（即类别不均衡）是一个常见且极具挑战性的问题。如果不对这种不均衡性进行处理，模型往往会偏向于样本量大的多数类，导致对样本量小的少数类别的识别性能低下。在岩性识别任务中，不同岩性类型的地质样本数量可能存在巨大差异，例如常见的砂岩、泥岩样本远多于某些稀有岩石类型。这种不均衡性会严重影响模型的泛化能力和实用性。

宏平均F1分数（Macro F1-Score）是处理多分类不平衡问题时一个重要的评估指标。它首先计算每个类别的F1分数，然后对所有类别的F1分数进行算术平均。这意味着Macro F1-Score平等对待每个类别，不受类别样本数量的影响，因此它能更真实地反映模型在所有类别上的综合性能，而非仅仅是多数类上的表现。本报告的调研重点正是围绕如何提升Macro F1-Score来展开，探索如何有效平衡所有类别的分类性能。

## 3. 核心发现

### 3.1 采样方法：平衡数据分布

采样方法通过改变训练数据的类别分布来减轻不平衡问题。主要分为过采样、欠采样和组合采样。

#### 3.1.1 过采样：SMOTE及其变种

**原理**：合成少数过采样技术（Synthetic Minority Over-sampling Technique, SMOTE）通过在少数类样本之间进行插值来人工合成新样本，而非简单复制。对于每个少数类样本`x`，它选择其`k`个近邻中的一个样本`~x`，然后在`x`和`~x`之间随机生成新样本`x_new = x + lambda * (~x - x)`，其中`lambda`是一个随机数（0到1之间）[[ref]](https://blog.csdn.net/wjjc1017/article/details/135361058) [[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**优缺点**：
*   **优点**：避免了简单复制少数类样本导致的过拟合问题，能够一定程度上弥补少数类样本的不足，提高模型对少数类的识别能力[[ref]](https://zhuanlan.zhihu.com/p/296632599)。
*   **缺点/挑战**：存在近邻选择的盲目性（K值难以确定），可能产生分布边缘化问题，合成样本可能模糊类别边界，且未考虑多数类样本分布的影响[[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**变种**：为克服SMOTE的缺陷，衍生出Borderline-SMOTE（专注于边界样本）、SMOTE-Tomek和SMOTE-ENN（结合了欠采样以清理噪声）等，这些变种旨在生成更有效的样本并优化类别边界[[ref]](https://www.cnblogs.com/massquantity/p/9382710.html)。

**与Macro F1-Score的关联**：过采样直接增加了少数类的样本数量，使得模型有更多机会学习少数类的特征，从而提高少数类的召回率和精度。由于Macro F1-Score是所有类别F1分数的平均，提升少数类性能直接有助于提高该指标。

#### 3.1.2 欠采样：Random Under-sampling, Tomek Links

**原理**：欠采样通过减少多数类样本的数量来实现类别平衡。最直接的方法是随机删除部分多数类样本（Random Under-sampling）。更复杂的欠采样技术如Tomek Links，识别互为最近邻的异类样本对（即Tomek Link），并移除多数类中的Tomek Link样本。这有助于清理类别边界上的噪声和重叠，使决策边界更清晰[[ref]](https://blog.csdn.net/wjjc1017/article/details/135361058) [[ref]](https://zhuanlan.zhihu.com/p/159080497)。

**优缺点**：
*   **优点**：减少了训练数据量，可能加速模型训练。Tomek Links能够清理类别边界，改善模型泛化能力[[ref]](https://blog.csdn.net/wjjc1017/article/details/135361058)。
*   **缺点**：随机欠采样可能导致多数类样本重要信息的丢失。其他基于原型选择的欠采样方法如NearMiss计算开销较大，且易受离群点影响[[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**与Macro F1-Score的关联**：欠采样通过减少多数类对模型的“压倒性”影响，使得模型能更平等地关注少数类。特别是Tomek Links等清理机制，通过优化类别边界，间接改善了少数类的分类性能，从而可能提升Macro F1-Score。

#### 3.1.3 过采样与欠采样结合 (如 SMOTE-Tomek)

**原理**：将过采样和欠采样结合使用，通常能够取得更好的平衡效果。例如，先用SMOTE增加少数类样本，再用Tomek Links减少多数类样本并清理噪声，使类别边界更清晰[[ref]](https://blog.csdn.net/wjjc1017/article/details/135361058)。

**优点**：综合了两种方法的优势，既能增加少数类样本量，又能清理数据和优化类别边界。有研究表明，SMOTE-Tomek等组合算法能同时提升模型分类能力和各类别识别率[](https://pmc.ncbi.nlm.nih.gov/articles/PMC9927194/) (snippet)。

**与Macro F1-Score的关联**：这种组合策略旨在更全面地解决类别不平衡，平衡样本数量并优化分类边界，从而在提升少数类性能的同时，维持或改善多数类性能，对Macro F1-Score产生积极的综合影响。

### 3.2 代价敏感学习：调整错误惩罚

代价敏感学习通过为不同类型的错误赋予非均等代价来解决类别不均衡问题，尤其适用于不同错误具有不同业务后果的场景。其核心在于使用代价矩阵`cost_ij`来量化将第`i`类样本预测为第`j`类样本的代价[[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**原理**：通过增加将少数类错分为多数类的代价，促使模型更倾向于正确识别少数类。例如，`cost_少数类_多数类 > cost_多数类_少数类` [[ref]](https://zhuanlan.zhihu.com/p/37942047)。

**实现方式**：
1.  **修改学习模型**：直接改造算法（如代价敏感决策树），从决策阈值、分裂标准或剪枝等方面引入代价矩阵[[ref]](https://zhuanlan.zhihu.com/p/296632599)。
2.  **后处理**：在模型训练完成后，根据代价矩阵对分类结果进行调整（需要模型输出概率）[[ref]](https://zhuanlan.zhihu.com/p/296632599)。
3.  **权重调整**：通过设置样本或类别权重，在训练过程中使分类器具备代价敏感性[[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**在XGBoost, LightGBM等模型中设置类别权重**：
*   **`class_weight`参数**：许多树形模型（如XGBoost、LightGBM、Random Forest）允许通过`class_weight`参数为不同类别设置权重。为少数类别分配更高的权重（即更高的误分类成本），可以促使模型更关注少数类的分类。例如，在Random Forest中设置`class_weight`可以有效提升模型性能[[ref]](https://zhuanlan.zhihu.com/p/37942047)。
*   **`scale_pos_weight`参数**：XGBoost和LightGBM在二分类问题中通常还提供`scale_pos_weight`参数，用于平衡正负样本的权重，即少数类（正类）与多数类（负类）的比例。例如，将其设为`count(negative class) / count(positive class)`，可以显著提高少数类的召回率[[ref]](https://cloud.tencent.com/developer/article/2550542) (implicit in the context of class weights).

**与Macro F1-Score的关联**：代价敏感学习直接改变了模型对不同类别错误分类的重视程度。通过对少数类错误施加更重的惩罚，模型会更倾向于正确分类少数类，从而提高其召回率和精度，最终提升Macro F1-Score，确保所有类别（包括少数类）的性能得到均衡考量。

### 3.3 算法与损失函数：内在机制优化

这一类方法通过改造算法核心机制或设计专门的损失函数来应对类别不均衡问题。

#### 3.3.1 Focal Loss

**原理**：Focal Loss是为解决极端类别不平衡问题而设计的损失函数，是标准交叉熵损失的改进版。它引入一个**调制因子**`(1 - p_t)^γ`来降低易分类样本（多数类或易于正确分类的样本）的权重，使模型训练时更聚焦于难以分类的样本（通常是少数类）[[ref]](https://zhuanlan.zhihu.com/p/296632599) [[ref]](https://kexue.fm/archives/7708/comment-page-1)。

**公式**：对于二分类，Focal Loss形式为：`FL(pt) = -αt (1 - pt)^γ log(pt)`
*   `pt`是模型预测概率。
*   `γ` (gamma)是调制因子中的超参数，调节降低易分类样本权重的速率。通常设置为2效果最佳[[ref]](https://zhuanlan.zhihu.com/p/296632599)。
*   `αt` (alpha)是平衡因子，用于平衡正负样本的比例不均，为少数类赋予更高权重。通常设置为0.25[[ref]](https://zhuanlan.zhihu.com/p/296632599)。

**优缺点**：
*   **优点**：在极端类别不平衡场景下（如目标检测），能显著提高少数类别的识别性能，强制模型关注“硬样本”以学习更精细的决策边界[[ref]](https://kexue.fm/archives/7708/comment-page-1)。
*   **缺点/挑战**：引入`α`和`γ`两个超参数，可能增加调参成本，且作为静态损失函数，超参数可能不适用于所有数据集[](http://www.360doc.com/content/22/1209/00/7673502_1059528034.shtml) (snippet).

**与Macro F1-Score的关联**：Focal Loss通过内在机制调整，使模型更高效地学习少数类和难分类样本的特征，直接提高了这些类别的分类性能。这直接促进了所有类别的F1-Score提升，从而显著提升Macro F1-Score。

#### 3.3.2 F1-Score 作为损失函数或优化目标

虽然F1-Score通常用作评价指标，但将其（或`1-F1Score`）直接作为损失函数进行优化也是一种策略，尤其是在语义分割等任务中有所应用[](https://blog.csdn.net/m0_37910705/article/details/102598832) (snippet)。这种方法使模型训练目标与Macro F1-Score最大化直接对齐，强制模型在训练阶段就关注所有类别的精确率和召回率平衡。但需要考虑F1-Score作为损失函数时的可导性问题。

#### 3.3.3 其他专门设计算法

*   **集成学习框架**：`BalancedBaggingClassifier`是一种集成学习方法，它允许在训练每个基分类器之前，对数据子集进行重采样，从而在集成层面解决不平衡问题[[ref]](https://zhuanlan.zhihu.com/p/296632599)。
*   **对现有算法的改进**：许多研究致力于改造现有分类器，使其能够适应不平衡数据，这与代价敏感学习对模型改造的思路相似。通过动态学习损失函数来调整各样本损失权重，可以实现在小批量内各类别样本总损失的平衡性[](https://html.rhhz.net/tis/html/201808004.htm) (snippet).

## 4. 结论

类别不均衡问题是岩性识别任务中影响模型性能的关键挑战。为了在Macro F1-Score这一全面评价指标下取得优异表现，需要综合运用数据层面的采样方法、模型层面的代价敏感学习和算法/损失函数层面的优化策略。每种策略都有其独特的侧重点和优势：

*   **采样方法**侧重于调整数据分布，以确保所有类别都能被充分学习，特别适合数据规模较小的少数类。结合过采样和欠采样的策略（如SMOTE-Tomek）通常能取得最佳效果。
*   **代价敏感学习**通过赋予不同错误类型不同的惩罚，直接引导模型更关注少数类的识别。在XGBoost、LightGBM等主流模型中设置`class_weight`或`scale_pos_weight`是简单有效的实践。
*   **Focal Loss**等专门设计的损失函数通过优化模型内在学习机制，使得模型能自动聚焦于难分类样本和少数类。它在极端不平衡场景下表现尤为突出。

在实际岩性识别应用中，选择单一策略或组合策略应根据数据集的具体特征、可用的计算资源以及对模型可解释性的需求进行权衡。例如，对于严重不平衡且数据量庞大的任务，Focal Loss可能非常有效；而对于中度不平衡问题，采样方法结合代价敏感的树模型可能更为稳健。未来的研究可以探索更自适应的混合策略，以及将F1-Score本身更好地融入到端到端优化流程中，以期在复杂的岩性识别场景中实现更优秀的Macro F1-Score。

## 5. 参考文献
1.  https://blog.csdn.net/wjjc1017/article/details/135361058
2.  https://zhuanlan.zhihu.com/p/296632599
3.  https://www.cnblogs.com/massquantity/p/9382710.html
4.  https://zhuanlan.zhihu.com/p/159080497
5.  https://pmc.ncbi.nlm.nih.gov/articles/PMC9927194/
6.  https://zhuanlan.zhihu.com/p/37942047
7.  https://cloud.tencent.com/developer/article/2550542
8.  https://www.cnblogs.com/apachecn/p/19073428
9.  https://kexue.fm/archives/7708/comment-page-1
10. http://www.360doc.com/content/22/1209/00/7673502_1059528034.shtml
11. https://blog.csdn.net/m0_37910705/article/details/102598832
12. https://html.rhhz.net/tis/html/201808004.htm