"""
ç»Ÿä¸€é¢„æµ‹è„šæœ¬ - ä¸­å›½çŸ³åŒ–AIç«èµ›æ²¹äº•å«æ°´ç‡é¢„æµ‹
æ•´åˆäº†æ ‡å‡†é¢„æµ‹å’Œæ™ºèƒ½åŸºçº¿é¢„æµ‹åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import argparse
import logging
from pathlib import Path
import pickle
import warnings
warnings.filterwarnings('ignore')

from config import OUTPUT_PATHS, TARGET_COL, TIME_COL, WELL_COL, ID_COL
from data_loader import DataLoader

import joblib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_models_and_feature_engineer():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç‰¹å¾å·¥ç¨‹å™¨"""
    logger.info("åŠ è½½æ¨¡å‹å’Œç‰¹å¾å·¥ç¨‹å™¨...")
    
    # åŠ è½½ç‰¹å¾å·¥ç¨‹å™¨
    feature_engineer_path = OUTPUT_PATHS['models'] / 'feature_engineer.pkl'
    feature_engineer = None
    if feature_engineer_path.exists():
        try:
            feature_engineer = joblib.load(feature_engineer_path)
            logger.info("ç‰¹å¾å·¥ç¨‹å™¨åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.warning(f"ç‰¹å¾å·¥ç¨‹å™¨åŠ è½½å¤±è´¥: {e}")
    else:
        logger.warning(f"ç‰¹å¾å·¥ç¨‹å™¨æ–‡ä»¶ä¸å­˜åœ¨: {feature_engineer_path}")
    
    # åŠ è½½æ¨¡å‹
    models = {}
    model_files = {
        'lightgbm': 'lightgbm_model.pkl',
        'xgboost': 'xgboost_model.pkl',
        'ensemble': 'ensemble_model.pkl'
    }
    
    for name, filename in model_files.items():
        model_path = OUTPUT_PATHS['models'] / filename
        if model_path.exists():
            try:
                models[name] = joblib.load(model_path)
                logger.info(f"{name} æ¨¡å‹åŠ è½½å®Œæˆ")
            except Exception as e:
                logger.warning(f"{name} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        else:
            logger.warning(f"{name} æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    return models, feature_engineer

def prepare_prediction_data_standard(data_loader, feature_engineer):
    """ä½¿ç”¨æ ‡å‡†ç‰¹å¾å·¥ç¨‹å‡†å¤‡é¢„æµ‹æ•°æ®"""
    logger.info("ä½¿ç”¨æ ‡å‡†ç‰¹å¾å·¥ç¨‹å‡†å¤‡é¢„æµ‹æ•°æ®...")
    val_df = data_loader.data['validation'].copy()
    val_features = feature_engineer.create_all_features(val_df, is_training=False)
    val_features = feature_engineer.transform_select_features(val_features)
    return val_features, val_df

def load_models(model_names: list, models_dir: Path) -> dict:
    """åŠ è½½æŒ‡å®šåç§°çš„æ¨¡å‹"""
    models = {}
    for name in model_names:
        model_path = models_dir / f'{name}_model.pkl'
        if model_path.exists():
            try:
                with open(model_path, 'rb') as f:
                    models[name] = joblib.load(f)
                logger.info(f"âœ… æ¨¡å‹ '{name}' åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹ '{name}' åŠ è½½å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ æ¨¡å‹ '{name}' æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}")
    return models

def make_predictions(models: dict, val_df: pd.DataFrame, val_features: pd.DataFrame, model_type: str):
    """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    logger.info(f"ä½¿ç”¨æ¨¡å‹ '{model_type}' è¿›è¡Œé¢„æµ‹...")
    
    model = models.get(model_type)
    if model is None:
        logger.error(f"æ¨¡å‹ '{model_type}' ä¸å¯ç”¨")
        return None

    # å‡†å¤‡ç‰¹å¾
    feature_cols = model.get_feature_names()
    X_val = val_features[feature_cols]
    
    predictions = model.predict(X_val)
    predictions = np.clip(predictions, 0, 100) # é¢„æµ‹å€¼è£å‰ª
    
    logger.info("é¢„æµ‹å®Œæˆ")
    return predictions

def create_submission_file(val_df: pd.DataFrame, predictions: np.ndarray, output_path: Path):
    """åˆ›å»ºæäº¤æ–‡ä»¶"""
    logger.info(f"åˆ›å»ºæäº¤æ–‡ä»¶åˆ°: {output_path}")
    submission_df = val_df[[ID_COL]].copy()
    submission_df[TARGET_COL] = predictions
    submission_df.to_csv(output_path, index=False)
    logger.info("æäº¤æ–‡ä»¶åˆ›å»ºæˆåŠŸ")
    return submission_df

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ²¹äº•å«æ°´ç‡é¢„æµ‹ç»“æœ')
    parser.add_argument('--model', type=str, default='lightgbm', 
                       choices=['lightgbm', 'xgboost', 'ensemble'],
                       help='ä½¿ç”¨çš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--output', type=str, 
                       default=str(OUTPUT_PATHS['submissions'] / 'submission.csv'),
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, default='standard', 
                       choices=['standard'],
                       help='é¢„æµ‹æ¨¡å¼')
    
    args = parser.parse_args()
    
    logger.info("="*60)
    logger.info("å¼€å§‹ç»Ÿä¸€é¢„æµ‹æµç¨‹...")
    logger.info(f"é¢„æµ‹æ¨¡å¼: {args.mode}")
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {args.model}")
    logger.info(f"è¾“å‡ºè·¯å¾„: {args.output}")
    logger.info("="*60)

    try:
        # åŠ è½½æ•°æ®
        data_loader = DataLoader()
        data_loader.load_all_data()
        logger.info(f"éªŒè¯æ•°æ®å½¢çŠ¶: {data_loader.data['validation'].shape}")

        # åŠ è½½ç‰¹å¾å·¥ç¨‹å™¨
        feature_engineer_path = OUTPUT_PATHS['models'] / 'feature_engineer.pkl'
        if not feature_engineer_path.exists():
            logger.error(f"æœªæ‰¾åˆ°ç‰¹å¾å·¥ç¨‹å™¨: {feature_engineer_path}")
            return
        feature_engineer = joblib.load(feature_engineer_path)
        logger.info("âœ… ç‰¹å¾å·¥ç¨‹å™¨åŠ è½½æˆåŠŸ")

        # å‡†å¤‡é¢„æµ‹æ•°æ®
        val_features, val_df = prepare_prediction_data_standard(data_loader, feature_engineer)

        # åŠ è½½æ¨¡å‹
        model_names = ['lightgbm', 'xgboost', 'ensemble']
        models = load_models(model_names, OUTPUT_PATHS['models'])
        if not models:
            logger.error("æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œæ— æ³•ç»§ç»­é¢„æµ‹ã€‚")
            return

        # è¿›è¡Œé¢„æµ‹
        predictions = make_predictions(models, val_df, val_features, args.model)

        # åˆ›å»ºæäº¤æ–‡ä»¶
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        submission_df = create_submission_file(val_df, predictions, output_path)

        logger.info("="*60)
        logger.info("ğŸ¯ é¢„æµ‹æµç¨‹å®Œæˆï¼")
        logger.info(f"ğŸ“ æœ€ç»ˆæäº¤æ–‡ä»¶: {output_path.absolute()}")
        logger.info("="*60)

    except Exception as e:
        logger.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()